{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16aa29e4-3ad2-4e4b-a118-21073b0a96fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3318b92-35cd-4167-8d8c-bd3b0ff06732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from tensorflow.keras.models import load_model\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80ddde-eb04-40a3-8732-41e7093e3151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7b7931-ad3e-4150-8b19-d9618d9ce13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(img_array):\n",
    "    \"\"\"\n",
    "    Resize and normalize an image array, and add a batch dimension.\n",
    "\n",
    "    Parameters:\n",
    "        img_array (numpy.ndarray): The image array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The processed image array with an added batch dimension.\n",
    "    \"\"\"\n",
    "    if isinstance(img_array, str):\n",
    "        # If img_array is a path, read the image using cv2\n",
    "        img = cv2.imread(img_array)\n",
    "    else:\n",
    "        # If img_array is already an array, use it directly\n",
    "        img = img_array\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(\"Failed to load the image.\")\n",
    "\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to (224, 224)\n",
    "    img = img / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "\n",
    "# Function to create a perturbed version of the image based on the LIME mask\n",
    "def perturb_image(img, mask):\n",
    "    \"\"\"\n",
    "    Create a perturbed(modified) version of the image by setting selected superpixels to 0 based on the LIME mask.\n",
    "\n",
    "    Parameters:\n",
    "        img (numpy.ndarray): The original image array.\n",
    "        mask (numpy.ndarray): The LIME mask indicating the superpixels to be perturbed.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The perturbed image array.\n",
    "    \"\"\"\n",
    "    perturbed_img = img.copy()  # Create a copy of the original image\n",
    "    perturbed_img[mask == 1] = 0  # Set the superpixels in the mask to 0\n",
    "\n",
    "    return perturbed_img\n",
    "\n",
    "# Function to display lime predictions\n",
    "def explain_prediction_lime(model, img_path, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Explain a model's prediction using LIME (Local Interpretable Model-agnostic Explanations).\n",
    "\n",
    "    Parameters:\n",
    "    - model (keras.Model): The trained model.\n",
    "    - img_path (str): Path to the image to be explained.\n",
    "    - class_index (int): Index of the target class.\n",
    "    - num_samples (int): Number of samples to generate for LIME.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing the LIME segmented image and the LIME explanation.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = load_and_preprocess_image(img_path)\n",
    "\n",
    "    # Save the original stdout\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    # Create a buffer to capture stdout\n",
    "    stdout_buffer = io.StringIO()\n",
    "\n",
    "    # Redirect stdout to the buffer\n",
    "    with redirect_stdout(stdout_buffer):\n",
    "        # Define the LIME explainer for image classification\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        # Explain the prediction\n",
    "        explanation = explainer.explain_instance(img[0], model.predict, top_labels=1, hide_color=0, num_samples=num_samples)\n",
    "\n",
    "    # Get LIME segmented image\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "\n",
    "    # Create a heatmap from the LIME mask\n",
    "    lime_segmented_img = mark_boundaries(temp / 2 + 0.5, mask)\n",
    "\n",
    "    # Get perturbed image\n",
    "    perturbed_img = perturb_image(img[0], mask)\n",
    "    perturbed_segmented_img = mark_boundaries(perturbed_img / 2 + 0.5, mask)\n",
    "\n",
    "   # Use lime_image's various functions\n",
    "    segmentation = explanation.segments\n",
    "\n",
    "    return lime_segmented_img, perturbed_segmented_img, segmentation\n",
    "\n",
    "# Function to get random image paths for both classes\n",
    "def get_random_image_paths(folder_path, num_images=4):\n",
    "    \"\"\"\n",
    "    Get a list of randomly selected image file paths from a folder.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing the images.\n",
    "        num_images (int): Number of image paths to randomly select.\n",
    "\n",
    "    Returns:\n",
    "        list: List of lists, each containing a randomly selected image file path.\n",
    "    \"\"\"\n",
    "    image_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    if len(image_paths) < num_images:\n",
    "        raise ValueError(\"Not enough images in the folder.\")\n",
    "\n",
    "    random_image_paths = random.sample(image_paths, num_images)\n",
    "    return [[path] for path in random_image_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337c2fd-1276-4bc7-8c8d-edcb9e3d4089",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5e77b-a87f-490d-ae43-827beb93aa3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Defining Gradio function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46138167-ba34-47d5-9431-6bd8382af405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_interface(image):\n",
    "    preprocessed_img = load_and_preprocess_image(image)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    threshold = 0.5  # Adjust the threshold as needed\n",
    "    binary_prediction = 1 if predictions[0][0] > threshold else 0\n",
    "    pred_class = \"Normal\" if binary_prediction == 0 else \"Pneumonia\"\n",
    "    \n",
    "    # Get the prediction accuracy\n",
    "    if binary_prediction == 1:\n",
    "        confidence  = predictions[0][0] * 100\n",
    "    else:\n",
    "        confidence  = (1 - predictions[0][0]) * 100\n",
    "\n",
    "    lime_segmented_img, perturbed_segmented_img, segmentation = explain_prediction_lime(model, image)\n",
    "\n",
    "    # Save the segmentation image to a temporary file and change cmap to viridis\n",
    "    temp_file_path = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False).name\n",
    "    plt.imsave(temp_file_path, segmentation, cmap='viridis')\n",
    "\n",
    "    return (\n",
    "        f\"Prediction: {pred_class}\\n confidence: {confidence :.2f}%\",\n",
    "        lime_segmented_img,\n",
    "        perturbed_segmented_img,\n",
    "        gr.Image(temp_file_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802e889-3910-465b-b3d6-037c219aa346",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba935c7-cc96-41f8-aa1a-2376b256002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter path of the best performing model\n",
    "model = load_model(\"Saved_models/InceptionV3_8_100.h5\")\n",
    "\n",
    "# Setting paths to each class in our test dataset\n",
    "normal_examples = r\"chest_xray\\test\\NORMAL\"\n",
    "pneumonia_examples = r\"chest_xray\\test\\PNEUMONIA\"\n",
    "\n",
    "# Definine example image limit\n",
    "eg_limit = 12\n",
    "\n",
    "# Defining input/output parameters for our gradio function\n",
    "image_input = gr.Image(sources = [\"upload\", \"clipboard\"])\n",
    "text_output = gr.Text(label=\"prediction_output\", placeholder=\"The Prediction along with the confidence will be displayed here\", show_copy_button=True)\n",
    "image_output_1 = gr.Image(type=\"pil\", label=\"Lime Segmented Image\", height=425, width=425)\n",
    "image_output_2 = gr.Image(type=\"pil\", label=\"Perturbed Image\", height=425, width=425)\n",
    "image_output_3 = gr.Image(type=\"pil\", label=\"Segmentation\", height=425, width=425)\n",
    "pred_output = [text_output, image_output_1, image_output_2, image_output_3]\n",
    "\n",
    "# Defining title, description and article\n",
    "\n",
    "title_text = \"Chest X-Ray Pneumonia Prediction\"\n",
    "\n",
    "desc_text = \"\"\"\n",
    "Upload a chest X-ray image to see the model's predictions and explanations.\\n\n",
    "You may select an example from below for a quick demo.\n",
    "\"\"\"\n",
    "\n",
    "article_text = (\n",
    "    \"<div style='text-align: center; font-size: 20px;'>\"\n",
    "    \"The first page contains examples of normal X-rays. <br>\"\n",
    "    \"The second page contains examples of X-rays with pneumonia. <br>\"\n",
    "    \"</div>\"\n",
    "    \"<div style='text-align: center; font-size: 15px;'>\"\n",
    "    \"Connect with me on \"\n",
    "    \"<a href='https://github.com/Kishor-Gulati' target='_blank'>GitHub</a>, \"\n",
    "    \"<a href='https://www.linkedin.com/in/kishor-gulati' target='_blank'>LinkedIn</a>, \"\n",
    "    \"<a href='https://leetcode.com/kanushgulati' target='_blank'>Leetcode</a>, \"\n",
    "    \"<a href='https://www.hackerrank.com/profile/kanushgulati' target='_blank'>Hackerrank</a>, \"\n",
    "    \"and <a href='mailto:kanushgulati@gmail.com'>G-mail</a>.\"\n",
    "    \"</div>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b7cc3-26a3-42ec-bdae-04fe509530f5",
   "metadata": {},
   "source": [
    "## Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e813b2f2-d741-40d1-a3e2-6d7c33ec873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://f9f3f9d0c9a64b15bb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f9f3f9d0c9a64b15bb.gradio.live\" width=\"100%\" height=\"1600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecery time we run this cell, random images will get populated in the Examples\n",
    "normal_examples_paths = get_random_image_paths(normal_examples, num_images=eg_limit)\n",
    "pneumonia_examples_paths = get_random_image_paths(pneumonia_examples, num_images=eg_limit)\n",
    "\n",
    "examples = normal_examples_paths + pneumonia_examples_paths\n",
    "\n",
    "# Creating an instance of gradio\n",
    "iface = gr.Interface(\n",
    "    fn=gr_interface,\n",
    "    inputs=image_input,\n",
    "    outputs=pred_output,\n",
    "    live=True,  # Enable live updates\n",
    "    title=title_text,\n",
    "    description=desc_text,\n",
    "    theme=gr.themes.Glass(), # theme=gr.themes.Soft()/Soft()\n",
    "    examples = examples,\n",
    "    examples_per_page = eg_limit,\n",
    "    article = article_text,\n",
    "    thumbnail = \"thumbnail.jpg\"\n",
    ")\n",
    "\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch(share=True, height = 1600, favicon_path = \"favicon.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
